import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import random  # âœ… Fix for visualization error

# ======================================
# ğŸ“‚ Dataset Loading Function
# ======================================
def load_npy_dataset(base_path):
    print(f"ğŸ–¼ï¸ Loading dataset from: {base_path}")

    train_image_dir = os.path.join(base_path, "train", "image")
    train_label_dir = os.path.join(base_path, "train", "label")
    val_image_dir = os.path.join(base_path, "val", "image")
    val_label_dir = os.path.join(base_path, "val", "label")

    # Load train data
    print("ğŸ“‚ Loading TRAIN data ...")
    train_images, train_labels = [], []
    for fname in os.listdir(train_image_dir):
        if fname.endswith(".npy"):
            img = np.load(os.path.join(train_image_dir, fname))
            label = np.load(os.path.join(train_label_dir, fname))
            train_images.append(img)
            train_labels.append(label)
    print(f"âœ… Loaded {len(train_images)} images and {len(train_labels)} labels from {train_image_dir}")

    # Load validation data
    print("ğŸ“‚ Loading VALIDATION data ...")
    val_images, val_labels = [], []
    for fname in os.listdir(val_image_dir):
        if fname.endswith(".npy"):
            img = np.load(os.path.join(val_image_dir, fname))
            label = np.load(os.path.join(val_label_dir, fname))
            val_images.append(img)
            val_labels.append(label)
    print(f"âœ… Loaded {len(val_images)} images and {len(val_labels)} labels from {val_image_dir}")

    # Convert to numpy arrays
    X = np.array(train_images + val_images)
    y = np.array(train_labels + val_labels)

    print(f"ğŸ¯ Total loaded images: {len(X)}, masks: {len(y)}")

    # Normalize images and masks
    X = X.astype("float32") / 255.0
    y = y.astype("float32") / 255.0

    # Ensure shape consistency (H, W, 1)
    if len(X.shape) == 3:
        X = np.expand_dims(X, axis=-1)
    if len(y.shape) == 3:
        y = np.expand_dims(y, axis=-1)

    return X, y

# ======================================
# ğŸ§  Model Definition
# ======================================
def build_segmentation_model(input_shape=(128, 128, 1)):
    model = Sequential([
        Input(shape=input_shape),
        Conv2D(32, (3, 3), activation='relu', padding='same'),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu', padding='same'),
        UpSampling2D((2, 2)),
        Conv2D(1, (3, 3), activation='sigmoid', padding='same')
    ])
    model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])
    return model

# ======================================
# âš™ï¸ Main Script
# ======================================
base_path = r"C:\Users\kaviya\Downloads\archive (4)\data"
X_full, y_full = load_npy_dataset(base_path)

# Split into train and validation sets
X_train_full, X_val_full, y_train_full, y_val_full = train_test_split(X_full, y_full, test_size=0.2, random_state=42)
print(f"ğŸ“Š Dataset split -> Train: {len(X_train_full)}, Test: {len(X_val_full)}")

# ======================================
# ğŸš€ Train the Model
# ======================================
model = build_segmentation_model(input_shape=X_train_full.shape[1:])
model.summary()

print("ğŸš€ Training the model...")
history = model.fit(
    X_train_full, y_train_full,
    validation_data=(X_val_full, y_val_full),
    epochs=5,
    batch_size=4
)
print("âœ… Training complete!")

# ======================================
# ğŸ’¾ Save Model
# ======================================
model.save("segmentation_model.h5")
print("ğŸ’¾ Model saved successfully!")

# ======================================
# ğŸ“ˆ Evaluate (IoU and Dice Score)
# ======================================
def iou_score(y_true, y_pred):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    union = np.sum(y_true_f) + np.sum(y_pred_f) - intersection
    return intersection / (union + 1e-7)

def dice_coefficient(y_true, y_pred):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    return (2. * intersection) / (np.sum(y_true_f) + np.sum(y_pred_f) + 1e-7)

# Predict on validation
y_pred_val = model.predict(X_val_full)
y_pred_val_bin = (y_pred_val > 0.5).astype(np.float32)

iou = iou_score(y_val_full, y_pred_val_bin)
dice = dice_coefficient(y_val_full, y_pred_val_bin)

print(f"ğŸ“ IoU Score: {iou:.4f}")
print(f"ğŸ¯ Dice Coefficient: {dice:.4f}")

# ======================================
# ğŸ§© Visualization
# ======================================
print("ğŸ§© Visualizing predictions...")

n_samples = 5
indices = random.sample(range(len(X_val_full)), n_samples)

plt.figure(figsize=(15, 10))
for i, idx in enumerate(indices):
    img = X_val_full[idx]
    mask = y_val_full[idx]
    pred_mask = model.predict(np.expand_dims(img, axis=0))[0]
    pred_mask_binary = (pred_mask > 0.5).astype(np.uint8)

    plt.subplot(n_samples, 3, 3*i + 1)
    plt.imshow(img.squeeze(), cmap='gray')
    plt.title("ğŸ–¼ï¸ Original Image")
    plt.axis('off')

    plt.subplot(n_samples, 3, 3*i + 2)
    plt.imshow(mask.squeeze(), cmap='gray')
    plt.title("ğŸ¯ True Mask")
    plt.axis('off')

    plt.subplot(n_samples, 3, 3*i + 3)
    plt.imshow(pred_mask_binary.squeeze(), cmap='gray')
    plt.title("ğŸ”® Predicted Mask")
    plt.axis('off')

plt.tight_layout()
plt.show()
